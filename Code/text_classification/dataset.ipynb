{"cells":[{"cell_type":"markdown","metadata":{},"source":["Scene-Text Detection"]},{"cell_type":"code","execution_count":169,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Loading all necessary libraries and modules\n","import os\n","import cv2\n","import csv\n","import math\n","import pickle\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from pprint import pprint\n","from matplotlib import gridspec\n","\n","import xml.etree.ElementTree as ET"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_data_dir(dataset_name: str):\n","    main_dir = os.getcwd().strip()\n","    dataset_dir = os.path.join(main_dir, 'dataset', dataset_name).replace(\"\\\\\", \"/\")\n","    return dataset_dir"]},{"cell_type":"code","execution_count":40,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["#dataset annotation csv preparation\n","def load_map_data(dataset: str, dataset_dir: str, image_format: str, annot_format: str):\n","    file_map_dict = {}\n","    annot_map_dict = {}\n","\n","    data_dirs = ['train', 'test']\n","\n","    for fname in os.listdir(dataset_dir):\n","        path = os.path.join(dataset_dir, fname).strip().replace(\"\\\\\", \"/\")\n","        all_files = os.listdir(path)\n","        if fname in data_dirs:\n","            img_files = [os.path.join(path, f).strip().replace(\"\\\\\", \"/\") for f in all_files if f[-len(image_format):] == image_format]\n","            file_map_dict[fname] = [os.path.relpath(f).strip().replace(\"\\\\\", \"/\") for f in img_files]\n","        if fname == 'Annotations':\n","            annot_files = [os.path.join(path, f).strip().replace(\"\\\\\", \"/\") for f in all_files if f[-len(annot_format):] == annot_format]\n","            annot_map_dict[fname] = [os.path.relpath(f).strip().replace(\"\\\\\", \"/\") for f in annot_files]\n","\n","    return file_map_dict, annot_map_dict\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["def extract_annot_paths(dataset_dir: str, file_map_dict: dict, annot_map_dict: dict, annot_format: str, prefix: str):\n","    train_annots = list()\n","    test_annots = list()\n","\n","    orig_annot_path = path = os.path.join(dataset_dir, 'Annotations').replace(\"\\\\\", \"/\")\n","\n","    for ind, each in enumerate([fs.split(\"/\")[-1][:-4] for fs in file_map_dict['train']] ):\n","        if prefix+each in [annot.split(\"/\")[-1][:-4] for annot in annot_map_dict['Annotations']]:\n","            train_annots.append(os.path.join(orig_annot_path, prefix+each+'.'+annot_format).replace(\"\\\\\", \"/\"))\n","\n","    for ind, each in enumerate([fs.split(\"/\")[-1][:-4] for fs in file_map_dict['test']] ):\n","        if prefix+each in [annot.split(\"/\")[-1][:-4] for annot in annot_map_dict['Annotations']]:\n","            test_annots.append(os.path.join(orig_annot_path, prefix+each+'.'+annot_format).replace(\"\\\\\", \"/\"))\n","\n","    return train_annots, test_annots"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["def parse_annot(file_path, dataset_name: str, prefix:str, suffix:str):\n","    if 'voc' in dataset_name:\n","        class_n = 'Non-Text'\n","        tree = ET.parse(file_path)\n","        root = tree.getroot()\n","\n","        size_elem = root.find('size')\n","        file_w = size_elem.find('width').text\n","        file_h = size_elem.find('height').text\n","\n","        name_elem = root.find('filename')\n","        filename = name_elem.text\n","\n","        obj_elem = root.findall('object')\n","        bbox_elem = []\n","        for obj in obj_elem:\n","            bbox = obj.find('bndbox')\n","            xmin = bbox.find('xmin').text\n","            ymin = bbox.find('ymin').text\n","            xmax = bbox.find('xmax').text\n","            ymax = bbox.find('ymax').text\n","            bbox_elem.append([filename, file_w, file_h, xmin,ymin, xmax, ymax, class_n])\n","\n","    elif 'icdar' in dataset_name:\n","        class_n = 'Text'\n","        with open(file_path, 'r', encoding='utf8') as f:\n","            filename = file_path.split(\"/\")[-1].split(prefix)[-1].split(\".\")[0]+suffix\n","            annot_data = []\n","            for dat in f.readlines():\n","                try:\n","                    temp = dat.split(\" \")\n","                    int(temp[0])\n","                except ValueError:\n","                    temp = dat.split(\", \")\n","\n","                annot_data.append(temp)\n","\n","            text_name = [each[-1].split('\"')[1] for each in annot_data]\n","            bbox_elem = [[filename]+each[:-1]+[class_n] for each in annot_data]\n","\n","    return bbox_elem"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[],"source":["def extract_annotations(train_annots:list, test_annots:list, dataset_name:str, filename:list, show_annot=False):\n","    annotation_voc = []\n","    for annots in train_annots:\n","        annotation_voc.extend(parse_annot(annots, dataset_name, prefix='gt_', suffix='.jpg'))\n","    for annots in test_annots:\n","        annotation_voc.extend(parse_annot(annots, dataset_name, prefix='gt_', suffix='.jpg'))\n","\n","    if show_annot:\n","        assert filename, \"a list of filename must be provided.\"\n","        for f_name in filename:\n","            print(\"Annotations found for image\", f_name, \"==>\")\n","            pprint([name for name in annotation_voc if name[0] == f_name])\n","            print(\"\")\n","    \n","    return annotation_voc"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["def display_annotations(dataset_name:str, dataset: str, file_map_dict: dict, annotation_voc: list, resize_attrib = (900, 600), n_images = 5):\n","    for ind, fpaths in enumerate(file_map_dict[dataset]):\n","        img = cv2.imread(fpaths)\n","        for annots in annotation_voc:\n","            if annots[0] == fpaths.split(\"/\")[-1]:\n","                fname = annots[0]\n","                if 'voc' in dataset_name:\n","                    cv2.rectangle(img, (int(annots[3]), int(annots[4])), \n","                                        (int(annots[5]), int(annots[6])), (255,0,0), 2)\n","                if 'icdar' in dataset_name:\n","                    cv2.rectangle(img, (int(annots[1]), int(annots[2])), \n","                                        (int(annots[3]), int(annots[4])), (255,0,0), 2)\n","        print(\"Displaying\",fname, \"from\", dataset+\"ing dataset: \")\n","        print(\"Info: \")\n","        print(\"size=(h, w)\", img.shape[:2], end=\"\\n\\n\")\n","\n","        img = cv2.resize(img, resize_attrib)\n","        cv2.imshow(\"image\", img)\n","        cv2.waitKey(0)\n","        cv2.destroyAllWindows()\n","        if n_images == \"all\":\n","            pass\n","        else:\n","            if ind == n_images:\n","                break"]},{"cell_type":"code","execution_count":193,"metadata":{},"outputs":[],"source":["def get_annot_csv(dataset_dir: str,\n","                dataset: str,\n","                file_map_dict: dict,\n","                csv_data: list,\n","                filename: str,\n","                header = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']):\n","    to_csv = csv_data.copy()\n","    to_csv = [header]+to_csv\n","\n","    if dataset:\n","        all_filenames = [fnames.split(\"/\")[-1] for fnames in file_map_dict[dataset]]\n","\n","    with open(os.path.join(dataset_dir, filename).replace(\"\\\\\", \"/\"), 'w', encoding='utf8', newline='') as f:\n","        for row in to_csv:\n","            if not dataset:\n","                for x in row:\n","                    f.write(x + ',')\n","                f.write('\\n')\n","            else:\n","                if row[0] in all_filenames:\n","                    for x in row:\n","                        f.write(x + ',')\n","                    f.write('\\n')           "]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory to extract data ==>  e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013\n","\n","Total annotations found:  390\n","Total training images found:  300\n","Total testimg images found:  90\n"]}],"source":["dataset_name = \"icdar-2013\"\n","dataset_dir = get_data_dir(dataset_name)\n","\n","print(\"Directory to extract data ==> \", dataset_dir, end=\"\\n\\n\")\n","\n","file_map_dict, annot_map_dict = load_map_data(dataset_name, dataset_dir, \"jpg\", \"txt\")\n","\n","print(\"Total annotations found: \", len(annot_map_dict['Annotations']))\n","print(\"Total training images found: \", len(file_map_dict['train']))\n","print(\"Total testimg images found: \", len(file_map_dict['test']))"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 5 training annotation files found:  ['e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_100.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_101.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_102.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_103.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_104.txt']\n","\n","Top 5 testimg annotation files found:  ['e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_img_100.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_img_101.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_img_102.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_img_103.txt', 'e:/Gustovalley/PhD Projects/Text segmentation/Git-Repo/Code/text_classification/dataset/icdar-2013/Annotations/gt_img_104.txt']\n"]}],"source":["train_annots, test_annots = extract_annot_paths(dataset_dir, file_map_dict, annot_map_dict, \"txt\", prefix='gt_')\n","\n","print(\"Top 5 training annotation files found: \", train_annots[:5], end=\"\\n\\n\")\n","print(\"Top 5 testimg annotation files found: \", test_annots[:5])"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Annotations found for image img_98.jpg ==>\n","[['img_98.jpg', '1012', '350', '1145', '370', 'Text'],\n"," ['img_98.jpg', '553', '568', '700', '611', 'Text'],\n"," ['img_98.jpg', '213', '651', '1037', '749', 'Text'],\n"," ['img_98.jpg', '328', '773', '490', '825', 'Text'],\n"," ['img_98.jpg', '516', '767', '610', '823', 'Text'],\n"," ['img_98.jpg', '633', '767', '731', '838', 'Text'],\n"," ['img_98.jpg', '757', '767', '926', '822', 'Text']]\n","\n","Annotations found for image img_99.jpg ==>\n","[['img_99.jpg', '423', '742', '446', '758', 'Text'],\n"," ['img_99.jpg', '462', '743', '513', '761', 'Text'],\n"," ['img_99.jpg', '531', '744', '651', '762', 'Text'],\n"," ['img_99.jpg', '667', '745', '696', '762', 'Text'],\n"," ['img_99.jpg', '713', '745', '819', '763', 'Text'],\n"," ['img_99.jpg', '835', '744', '894', '763', 'Text'],\n"," ['img_99.jpg', '912', '743', '1043', '767', 'Text'],\n"," ['img_99.jpg', '363', '769', '516', '791', 'Text'],\n"," ['img_99.jpg', '537', '772', '594', '793', 'Text'],\n"," ['img_99.jpg', '615', '773', '695', '794', 'Text'],\n"," ['img_99.jpg', '714', '773', '817', '793', 'Text'],\n"," ['img_99.jpg', '833', '772', '911', '793', 'Text'],\n"," ['img_99.jpg', '929', '769', '1103', '792', 'Text']]\n","\n"]}],"source":["annotation_voc = extract_annotations(train_annots, test_annots, dataset_name, [\"img_98.jpg\", \"img_99.jpg\"], True)"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Displaying 100.jpg from training dataset: \n","Info: \n","size=(h, w) (480, 640)\n","\n","Displaying 101.jpg from training dataset: \n","Info: \n","size=(h, w) (480, 640)\n","\n","Displaying 102.jpg from training dataset: \n","Info: \n","size=(h, w) (480, 640)\n","\n","Displaying 103.jpg from training dataset: \n","Info: \n","size=(h, w) (480, 640)\n","\n","Displaying 104.jpg from training dataset: \n","Info: \n","size=(h, w) (640, 480)\n","\n","Displaying 105.jpg from training dataset: \n","Info: \n","size=(h, w) (1280, 960)\n","\n"]}],"source":["display_annotations(dataset_name, 'train', file_map_dict, annotation_voc, n_images=5)"]},{"cell_type":"code","execution_count":196,"metadata":{},"outputs":[],"source":["get_annot_csv(dataset_dir, 'train', file_map_dict, csv_data = annotation_voc, filename= '../annotation_train.csv')\n","get_annot_csv(dataset_dir, 'test', file_map_dict, csv_data = annotation_voc, filename= '../annotation_test.csv')\n","get_annot_csv(dataset_dir, False, file_map_dict, csv_data = annotation_voc, filename= '../annotation_icdar.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('phd_proj')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"46365b1404efb71e566f25b0a99430559c9c0312aeb5c4af39f313826d3b520e"}}},"nbformat":4,"nbformat_minor":4}
